{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q71ofDDJ6-RX"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import numpy as py\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Embedding , LSTM , SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read and load data\n",
        "data = pd.read_csv('/content/Sentiment.csv')\n"
      ],
      "metadata": {
        "id": "vAZ6fdnb9bE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#select features important\n",
        "data = data[['text','sentiment']]"
      ],
      "metadata": {
        "id": "fkt-_9su-H45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### expcetion neutral case from lable sentiment\n",
        "data = data[data.sentiment != 'Neutral']\n",
        "#### lambda func:- create function without name\n",
        "#### where x is parametar, x.lower is the return\n",
        "####  data['text'].apply represent call by value to x\n",
        "data['text']= data['text'].apply(lambda x: x.lower()) # transformation upper case to lower\n",
        "data['text']= data['text'].apply(lambda x:re.sub(r'[^a-zA-Z0-9\\s]','',x)) #Determine the things I want in the speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIojU5sW-SvK",
        "outputId": "48e93242-3b28-45d3-ca10-67c55496f6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-718aca211509>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text']= data['text'].apply(lambda x: x.lower()) # transformation upper case to lower\n",
            "<ipython-input-5-718aca211509>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text']= data['text'].apply(lambda x:re.sub(r'[^a-zA-Z0-9\\s]','',x)) #Determine the things I want in the speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in data.iterrows():\n",
        "  row[0] = row[0].replace('rt',' ') # replace rt with a space"
      ],
      "metadata": {
        "id": "9daW9-K0_h2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features=2000 # the variable is represent dictionary\n",
        "\n",
        "## tokenizer is a class Responsible for dividing the sentence, as it divides every space\n",
        "## create object from tokenizer class and give it two variables, one is the size of the dictionary and the other is the thing I want to divide from\n",
        "tokenizer= Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "x = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "x= pad_sequences(x) ## To make all sentences equal, where each sentence will be equal to the longest sentence in text label"
      ],
      "metadata": {
        "id": "E1xfIOmY_7qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim =128 ## represent numbers of weights\n",
        "lstm_out=196 ## represent numbers of units\n",
        "\n",
        "model= Sequential()\n",
        "#### Embedding is the first layer in the model Responsible for give Giving words that are close or that have a relationship between them similar values\n",
        "### max_features --> dictionary\n",
        "### embed_dim --> numbers of weights\n",
        "## input_length --> It represents the input of the layer\n",
        "model.add(Embedding(max_features, embed_dim,input_length=x.shape[1]))\n",
        "\n",
        "### drop from output of the Embedding layers to  prevent happening overfitting\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "\n",
        "### lstm layers tekes 3 variables\n",
        "### lstm_out --> numbers of units\n",
        "### dropout --> represent a random drop to the input\n",
        "### recurrent_dropout--> represent a random drop to the recurrent\n",
        "model.add(LSTM(lstm_out, dropout=0.2 , recurrent_dropout= 0.2))\n",
        "\n",
        "model.add(Dense(2,'softmax'))\n",
        "model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "\n",
        "y=pd.get_dummies(data['sentiment']).values ## one hot incoding\n"
      ],
      "metadata": {
        "id": "BQfLbkiaBVzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test ,y_train, y_test= train_test_split(x,y, test_size=0.2,random_state=32)\n"
      ],
      "metadata": {
        "id": "5WWh65LjEHSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5 , batch_size=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic-CWxT6EmuU",
        "outputId": "bbe39935-4fee-489e-e8af-9e8e48fbebea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "287/287 [==============================] - 54s 172ms/step - loss: 0.4207 - accuracy: 0.8237\n",
            "Epoch 2/5\n",
            "287/287 [==============================] - 51s 178ms/step - loss: 0.3151 - accuracy: 0.8646\n",
            "Epoch 3/5\n",
            "287/287 [==============================] - 53s 185ms/step - loss: 0.2759 - accuracy: 0.8849\n",
            "Epoch 4/5\n",
            "287/287 [==============================] - 49s 171ms/step - loss: 0.2504 - accuracy: 0.8928\n",
            "Epoch 5/5\n",
            "287/287 [==============================] - 49s 172ms/step - loss: 0.2279 - accuracy: 0.9061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x792d88563ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}